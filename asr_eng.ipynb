{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f29SVKk6mTQm"
   },
   "source": [
    "## Installing the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZclyAx0NHI2",
    "outputId": "a342d4c9-278e-4699-f9fb-3c3a56634c62",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio==0.9.0\n",
      "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n",
      "\u001b[?25hCollecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
      "\u001b[?25hCollecting comet-ml==3.20.0\n",
      "  Downloading comet_ml-3.20.0-py2.py3-none-any.whl (302 kB)\n",
      "\u001b[K     |████████████████████████████████| 302 kB 64.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.10.0.2)\n",
      "Collecting everett[ini]>=1.0.1\n",
      "  Downloading everett-2.0.1-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from comet-ml==3.20.0) (1.15.0)\n",
      "Collecting requests-toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.8 MB/s \n",
      "\u001b[?25hCollecting semantic-version>=2.8.0\n",
      "  Downloading semantic_version-2.8.5-py2.py3-none-any.whl (15 kB)\n",
      "Collecting dulwich>=0.20.6\n",
      "  Downloading dulwich-0.20.26-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (546 kB)\n",
      "\u001b[K     |████████████████████████████████| 546 kB 68.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from comet-ml==3.20.0) (2.23.0)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml==3.20.0) (7.352.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml==3.20.0) (2.6.0)\n",
      "Collecting websocket-client>=0.55.0\n",
      "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from comet-ml==3.20.0) (1.13.3)\n",
      "Collecting wurlitzer>=1.0.2\n",
      "  Downloading wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from dulwich>=0.20.6->comet-ml==3.20.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.7/dist-packages (from dulwich>=0.20.6->comet-ml==3.20.0) (1.24.3)\n",
      "Collecting configobj\n",
      "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet-ml==3.20.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet-ml==3.20.0) (3.0.4)\n",
      "Building wheels for collected packages: configobj\n",
      "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34546 sha256=d5580ee70a3c7c2fff4dfd1eb5113f3f53cff541cca8cc48e8effbd5a4f6c339\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
      "Successfully built configobj\n",
      "Installing collected packages: everett, configobj, wurlitzer, websocket-client, torch, semantic-version, requests-toolbelt, dulwich, torchaudio, comet-ml\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
      "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
      "Successfully installed comet-ml-3.20.0 configobj-5.0.6 dulwich-0.20.26 everett-2.0.1 requests-toolbelt-0.9.1 semantic-version-2.8.5 torch-1.9.0 torchaudio-0.9.0 websocket-client-1.2.1 wurlitzer-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio==0.9.0 torch==1.9.0 comet-ml==3.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "FA99A3RbNHI3"
   },
   "source": [
    "## GPU runtime\n",
    "If you are using a GPU runtime, this will let you know what GPU and how much memory is available. Adjust your batch_size depending on which GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YB_kbpEQNHI4",
    "outputId": "f4d34149-23dc-4fc8-a4bd-4c94358af419",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 13 21:35:24 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "mv3TrZPsNHI5"
   },
   "source": [
    "## Setting up your data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l6uBf5_JNHI5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from comet_ml import Experiment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cbtYfXkNXvP"
   },
   "source": [
    "## Importing util module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_i8G3oUbNbE6",
    "outputId": "6d81132f-9ffe-465a-e0d2-01e08530e7f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-lLCs59uPQyG"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/ASR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VK0IWoEpPck6"
   },
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "xq0P1JNZNHI7"
   },
   "source": [
    "## Setting up Comet\n",
    "If you have a comet account, fill in teh api key, project name and experiment name below. You can create an account at [comet.ml](comet.ml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ch38h3-QNHI7",
    "outputId": "26d14034-f2d9-4584-ecdd-d95c236701b8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Couldn't find a Git repository in '/content' and lookings in parents. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/joker666/speech-recog/c23bc95337434f64bf27a4843d6e4626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comet_api_key = \"gnrNd5OT5wP3KRctk4grI4ODw\" # add your api key here\n",
    "project_name = \"speech-recog\"\n",
    "experiment_name = \"speechrecognition-colab\"\n",
    "\n",
    "if comet_api_key:\n",
    "    experiment = Experiment(api_key=comet_api_key, project_name=project_name, parse_args=False)\n",
    "    experiment.set_name(experiment_name)\n",
    "else:\n",
    "    experiment = Experiment(api_key='dummy_key', disabled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "oQ0wJ7eZNHI8"
   },
   "source": [
    "## The Model\n",
    "Base off of Deep Speech 2 with some personal improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c7vQ4tyNHI8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting hierarchical features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.res_cnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.bi_rnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # bi_rnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.res_cnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.bi_rnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "_bb8ZxbCNHI9"
   },
   "source": [
    "## The Training and Evaluating Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9gpPNYWNHI-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment: Experiment):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    with experiment.train():\n",
    "        for batch_idx, _data in enumerate(train_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data\n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            loss.backward()\n",
    "\n",
    "            experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
    "            experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            iter_meter.step()\n",
    "            if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(spectrograms), data_len,\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, iter_meter, experiment: Experiment):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    with experiment.test():\n",
    "        with torch.no_grad():\n",
    "            for i, _data in enumerate(test_loader):\n",
    "                spectrograms, labels, input_lengths, label_lengths = _data\n",
    "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "                output = model(spectrograms)  # (batch, time, n_class)\n",
    "                output = F.log_softmax(output, dim=2)\n",
    "                output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "                loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "                test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "                decoded_predictions, decoded_targets = util.greedy_decoder(output.transpose(0, 1),\n",
    "                                                                           text_transform,\n",
    "                                                                           labels, label_lengths)\n",
    "                for j in range(len(decoded_predictions)):\n",
    "                    test_cer.append(util.cer(decoded_targets[j], decoded_predictions[j]))\n",
    "                    test_wer.append(util.wer(decoded_targets[j], decoded_predictions[j]))\n",
    "\n",
    "\n",
    "    avg_cer = sum(test_cer)/len(test_cer)\n",
    "    avg_wer = sum(test_wer)/len(test_wer)\n",
    "    experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
    "    experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
    "    experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Qtf6q8aINHI_"
   },
   "source": [
    "## Train\n",
    "This will download the data on first run and may take a while.\n",
    "\n",
    "If you have Comet.ml setup, you can start seeing your progress in the comet cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gohQX7IINHI_",
    "outputId": "04420401-ae91-480a-aa5f-c7da4fe09ea3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:433: UserWarning:\n",
      "\n",
      "At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Model Parameters 23705373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:1290: UserWarning:\n",
      "\n",
      "To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 6.524250\n",
      "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 2.901600\n",
      "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 2.888599\n",
      "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 2.845330\n",
      "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 2.873494\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.913153\n",
      "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 2.884891\n",
      "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 2.863264\n",
      "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 2.933559\n",
      "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 2.856892\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.840950\n",
      "Train Epoch: 1 [11000/28539 (39%)]\tLoss: 2.714109\n",
      "Train Epoch: 1 [12000/28539 (42%)]\tLoss: 2.535183\n",
      "Train Epoch: 1 [13000/28539 (46%)]\tLoss: 2.311012\n",
      "Train Epoch: 1 [14000/28539 (49%)]\tLoss: 2.140967\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.046268\n",
      "Train Epoch: 1 [16000/28539 (56%)]\tLoss: 1.945058\n",
      "Train Epoch: 1 [17000/28539 (60%)]\tLoss: 1.964478\n",
      "Train Epoch: 1 [18000/28539 (63%)]\tLoss: 1.813784\n",
      "Train Epoch: 1 [19000/28539 (67%)]\tLoss: 1.809998\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 1.836439\n",
      "Train Epoch: 1 [21000/28539 (74%)]\tLoss: 1.830451\n",
      "Train Epoch: 1 [22000/28539 (77%)]\tLoss: 1.596612\n",
      "Train Epoch: 1 [23000/28539 (81%)]\tLoss: 1.619649\n",
      "Train Epoch: 1 [24000/28539 (84%)]\tLoss: 1.608971\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 1.585914\n",
      "Train Epoch: 1 [26000/28539 (91%)]\tLoss: 1.432842\n",
      "Train Epoch: 1 [27000/28539 (95%)]\tLoss: 1.529283\n",
      "Train Epoch: 1 [28000/28539 (98%)]\tLoss: 1.494804\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 1.3459, Average CER: 0.433701 Average WER: 0.9107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "batch_size = 10\n",
    "epochs = 1\n",
    "train_url = \"train-clean-100\"\n",
    "test_url = \"test-clean\"\n",
    "\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "text_transform = util.TextTransform()\n",
    "\n",
    "\n",
    "h_params = {\n",
    "    \"n_cnn_layers\": 3,\n",
    "    \"n_rnn_layers\": 5,\n",
    "    \"rnn_dim\": 512,\n",
    "    \"n_class\": 29,\n",
    "    \"n_feats\": 128,\n",
    "    \"stride\":2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs\n",
    "}\n",
    "\n",
    "experiment.log_parameters(h_params)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(7)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "if not os.path.isdir(\"./data\"):\n",
    "    os.makedirs(\"./data\")\n",
    "\n",
    "train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                               batch_size=h_params['batch_size'],\n",
    "                               shuffle=True,\n",
    "                               collate_fn=lambda x: util.data_processing(x, text_transform,\n",
    "                                                                         train_audio_transforms,\n",
    "                                                                         valid_audio_transforms, 'train'),\n",
    "                               **kwargs)\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                              batch_size=h_params['batch_size'],\n",
    "                              shuffle=False,\n",
    "                              collate_fn=lambda x: util.data_processing(x, text_transform,\n",
    "                                                                        train_audio_transforms,\n",
    "                                                                        valid_audio_transforms, 'valid'),\n",
    "                              **kwargs)\n",
    "\n",
    "model = SpeechRecognitionModel(\n",
    "    h_params['n_cnn_layers'], h_params['n_rnn_layers'], h_params['rnn_dim'],\n",
    "    h_params['n_class'], h_params['n_feats'], h_params['stride'], h_params['dropout']\n",
    ").to(device)\n",
    "\n",
    "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), h_params['learning_rate'])\n",
    "criterion = nn.CTCLoss(blank=28).to(device)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=h_params['learning_rate'],\n",
    "                                          steps_per_epoch=int(len(train_loader)),\n",
    "                                          epochs=h_params['epochs'],\n",
    "                                          anneal_strategy='linear')\n",
    "\n",
    "iter_meter = util.IterMeter()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\n",
    "    test(model, device, test_loader, criterion, epoch, iter_meter, experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RNNxLDJNHJA",
    "outputId": "47e6c879-2c2f-40b9-edad-a90436848e5f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/joker666/speech-recog/c23bc95337434f64bf27a4843d6e4626\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     test_cer                   : 0.4337010690160993\n",
      "COMET INFO:     test_test_loss             : 1.3459090745176068\n",
      "COMET INFO:     test_wer                   : 0.9106666036681477\n",
      "COMET INFO:     train_learning_rate [5708] : (2.0000000000314905e-09, 0.000499887745556595)\n",
      "COMET INFO:     train_loss [6279]          : (1.3081644773483276, 8.301060676574707)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name : speechrecognition-colab\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size          : 10\n",
      "COMET INFO:     dropout             : 0.1\n",
      "COMET INFO:     epochs              : 1\n",
      "COMET INFO:     learning_rate       : 0.0005\n",
      "COMET INFO:     n_class             : 29\n",
      "COMET INFO:     n_cnn_layers        : 3\n",
      "COMET INFO:     n_feats             : 128\n",
      "COMET INFO:     n_rnn_layers        : 5\n",
      "COMET INFO:     rnn_dim             : 512\n",
      "COMET INFO:     stride              : 2\n",
      "COMET INFO:     test_batch_size     : 10\n",
      "COMET INFO:     test_dropout        : 0.1\n",
      "COMET INFO:     test_epochs         : 1\n",
      "COMET INFO:     test_learning_rate  : 0.0005\n",
      "COMET INFO:     test_n_class        : 29\n",
      "COMET INFO:     test_n_cnn_layers   : 3\n",
      "COMET INFO:     test_n_feats        : 128\n",
      "COMET INFO:     test_n_rnn_layers   : 5\n",
      "COMET INFO:     test_rnn_dim        : 512\n",
      "COMET INFO:     test_stride         : 2\n",
      "COMET INFO:     train_batch_size    : 10\n",
      "COMET INFO:     train_dropout       : 0.1\n",
      "COMET INFO:     train_epochs        : 1\n",
      "COMET INFO:     train_learning_rate : 0.0005\n",
      "COMET INFO:     train_n_class       : 29\n",
      "COMET INFO:     train_n_cnn_layers  : 3\n",
      "COMET INFO:     train_n_feats       : 128\n",
      "COMET INFO:     train_n_rnn_layers  : 5\n",
      "COMET INFO:     train_rnn_dim       : 512\n",
      "COMET INFO:     train_stride        : 2\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     os packages         : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "asr_eng.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
